##################################################
# Logstash + SCALA for SCAPI
#
# v1.0 	12/18/14	Doug McClure 	Initial Release
#
###############################################
#
# NOTES:
#
# 1. Determine which SCAPI log files you want to make use of. Some are more practical than others such as the four described below.
# 2. Update input section based upon how you will bring in SCAPI log files into logstash.  There are many options available to do this including the use of rsyslog/syslog-ng, logstash-forwarder, LFA or file inputs as shown below.
# 3. Update the patterns_dir parameter in each multiline and grok filter based on where you've placed the SCAPIPATTERNS grok pattern file.
# 4. Ensure that you set your host and path as needed for aggregation and consolidation in your SCALA datasource. 
# 5. Set a "final" tag to indicate all processing is done and message is ready to ship to SCALA via output
#
#################################################
#
# SCAPI Log Types
# 
#  	type => "SCAPI-TOPIC-DS" 	: TopicDataSourcescapi_log_DataSource.log
#	type => "SCAPI-STAT" 		: GrangerDetectionscapiFw_stat.log
#	type => "SCAPI-MODEL" 		: GrangerDetectionscapi_log_GrangerTrainWrapper.log
#	type => "SCAPI-BULK"		: All other SCAPI logs 
#
# Derived Types from logs
#
# READ
# MERGE
# OVERALL
# DATAAVAIL
#
###############################################

input {

	#tcp {
	#	port => 10515
	#	type => "SCAPIviaSYSLOG"
	#} #end tcp
		
	file {
		path => "/opt/logstash/scapi-logs/contentpacks/TopicDataSourcescapi_log_DataSource.log"
		start_position => "beginning"
		sincedb_path => "/dev/null"
		type => "SCAPI-TOPIC-DS"
	}
	
	file {
		path => "/opt/logstash/scapi-logs/contentpacks/GrangerDetectionscapiFw_stat.log"
		start_position => "beginning"
		sincedb_path => "/dev/null"
		type => "SCAPI-STAT"
	}
	
	file {
		path => "/opt/logstash/scapi-logs/contentpacks/GrangerDetectionscapi_log_GrangerTrainWrapper.log"
		start_position => "beginning"
		type => "SCAPI-MODEL"
	}

	file {
		path => "/opt/logstash/scapi-logs/bulk/*.log"
		start_position => "beginning"
		type => "SCAPI-BULK"
	}
} #end inputs

filter {

##############################################

# SCAPI TopicDataSourcescapi_log_DataSource.log

if [type] == "SCAPI-TOPIC-DS" {
	
	multiline {
		pattern => "^%{PITIMESTAMP}"
		patterns_dir => ["/opt/logstash/patterns"]
		negate => "true"
		what => "previous"
	} #end multi
	
	grok {
		match => { "message" => "%{TOPICGENERAL}" }
		match => { "message" => "%{TOPICDATAAVAIL}" }
		patterns_dir => ["/opt/logstash/patterns"]
		add_tag => ["SCAPI-TOPIC-DS-grokked"]
	} #end grok
	
	if "SCAPI-TOPIC-DS-grokked" in [tags] {
	
		#take timestampOrig (missing timezone) and convert it to @timestamp in proper ISO8601 format with timezone
	
		date {
			match => [ "Timestamp", "YYYY-MM-dd HH:mm:ss,SSS" ]
			target => "@timestamp"
		} #end date
		
		mutate {
			replace => [ "host", "SCAPI-TOPIC-GENERAL", "path", "SCAPI-TOPIC-GENERAL" ]
			add_tag => ["SCAPI-TOPIC-GENERAL-final"]
		} #end mutate
	} #end host/path setup
} #end SCAPI-TOPIC type	

##############################################

#file input 

if [type] == "SCAPI-STAT" {
	
	multiline {
		pattern => "^%{PITIMESTAMP}"
		patterns_dir => ["/opt/logstash/patterns"]
		negate => "true"
		what => "previous"
	} #end multi

	grok {
		match => { "message" => "%{READ}" }
		match => { "message" => "%{MERGE}" }
		match => { "message" => "%{OVERALL}" }
		match => { "message" => "%{DATAAVAIL}" }
		patterns_dir => ["/opt/logstash/patterns"]
        add_tag => ["SCAPI-STAT-grokked"]
	} #end grok
	
	if ![Process] { drop {} }
	
	if "SCAPI-STAT-grokked" in [tags] {
	
		#take timestampOrig (missing timezone) and convert it to @timestamp in proper ISO8601 format with timezone
	
		date {
			match => [ "Timestamp", "YYYY-MM-dd HH:mm:ss,SSS" ]
			target => "@timestamp"
		} #end date
		
		if [Process] == "Read" {
			mutate {
				replace => [ "type", "READ" ]
				replace => [ "host", "SCAPI-STAT-Read", "path", "SCAPI-STAT-Read"]
				add_tag => ["SCAPI-STAT-Read-final"]
			} #end mutate
		} #end Read
		
		if [Process] == "Merge" {
			mutate {
				replace => [ "type", "MERGE" ]
				replace => [ "host", "SCAPI-STAT-Merge", "path", "SCAPI-STAT-Merge"]
				add_tag => ["SCAPI-STAT-Merge-final"]
			} #end mutate
		}
		
		if [Process] == "Overall" {
			mutate {
				replace => [ "type", "OVERALL" ]
				replace => [ "host", "SCAPI-STAT-Overall", "path", "SCAPI-STAT-Overall"]
				add_tag => ["SCAPI-STAT-Overall-final"]
			} #end mutate
		}
		
		if [Process] == "DataAvail" {
			mutate {
				replace => [ "type", "DATAAVAIL" ]
				replace => [ "host", "SCAPI-STAT-DataAvail", "path", "SCAPI-STAT-DataAvail"]
				add_tag => ["SCAPI-STAT-DataAvail-final"]
			} #end mutate
		}
	} #end host/path setup
} #end type => "SCAPI-STAT"


##############################################

#	type => "SCAPI-MODEL" 		: GrangerDetectionscapi_log_GrangerTrainWrapper.log

if [type] == "SCAPI-MODEL" {
	
	multiline {
		pattern => "^%{PITIMESTAMP}"
		patterns_dir => ["/opt/logstash/patterns"]
		negate => "true"
		what => "previous"
	} #end multi
	
	grok {
		match => { "message" => "%{PIMODEL}" }
		patterns_dir => ["/opt/logstash/patterns"]
		add_tag => ["SCAPI-MODEL-grokked"]
	} #end grok
	
	if "SCAPI-MODEL-grokked" in [tags] {
	
		#take timestampOrig (missing timezone) and convert it to @timestamp in proper ISO8601 format with timezone
	
		date {
			match => [ "Timestamp", "YYYY-MM-dd HH:mm:ss,SSS" ]
			target => "@timestamp"
		} #end date
		
		mutate {
			replace => [ "host", "SCAPI-MODEL", "path", "SCAPI-MODEL"]
			add_tag => ["SCAPI-MODEL-final"]
		} #end mutate
	} #end host/path setup
} #end SCAPI-MODEL type	

##############################################

#bring in all over PI logs which don't have more specific parsing & annotation configured
	
if [type] == "SCAPI-BULK" {
	
	multiline {
		pattern => "^%{PITIMESTAMP}"
		patterns_dir => ["/opt/logstash/patterns"]
		negate => "true"
		what => "previous"
	} #end multi
	
	grok {
		match => { "message" => "%{PIPATTERN1}" }
		patterns_dir => ["/opt/logstash/patterns"]
		add_tag => ["SCAPI-BULK-grokked"]
	} #end grok
	
	if "SCAPI-BULK-grokked" in [tags] {
	
		#take timestampOrig (missing timezone) and convert it to @timestamp in proper ISO8601 format with timezone
	
		date {
			match => [ "Timestamp", "YYYY-MM-dd HH:mm:ss,SSS" ]
			target => "@timestamp"
		} #end date
		
		mutate {
			replace => [ "host", "SCAPI-BULK", "path", "SCAPI-BULK"]
			add_tag => ["SCAPI-BULK-final"]
		} #end mutate
	} #end host/path setup
} #end SCAPI-MODEL type		
	
	
##############################################
	
} #end filters

output {

###############################################	
#
#for new logstash scala outuput 

if "SCAPI-STAT-Read-final" in [tags] or "SCAPI-STAT-Merge-final" in [tags] or "SCAPI-STAT-Overall-final" in [tags] or "SCAPI-STAT-DataAvail-final" in [tags] or "SCAPI-TOPIC-GENERAL-final" in [tags] or "SCAPI-MODEL-final" in [tags] or "SCAPI-BULK-final" in [tags] {
	scala { 
		scala_url => "https://10.0.0.1:9987/Unity/DataCollector"
		scala_user => "unityadmin" 
		scala_password => "unityadmin" 
		batch_size => 500000
		idle_flush_time => 5 
		sequential_flush => true
		num_concurrent_writers => 5
		use_structured_api => true
		disk_cache_path => "/opt/logstash/cache/scapi"
		scala_fields => {
			"SCAPI-STAT-DataAvail@SCAPI-STAT-DataAvail" => "@timestamp,Process,Resources,KPIs,OfMaxKPIs,NoLongerAnalyzed,AlarmsSent"
			"SCAPI-STAT-Read@SCAPI-STAT-Read" => "@timestamp,Process,Group,Interval,NumberOfRows"
			"SCAPI-STAT-Merge@SCAPI-STAT-Merge" => "@timestamp,Process,Interval,NumberOfRows,QueueSize"
			"SCAPI-STAT-Overall@SCAPI-STAT-Overall" => "@timestamp,Process,IntervalsIn,DataIntervalsIn,IntervalsOut,Latency"
			"SCAPI-TOPIC-GENERAL@SCAPI-TOPIC-GENERAL,SCAPI-BULK@SCAPI-BULK" => "@timestamp,LogLevel,Process,LogMessage"
			"SCAPI-MODEL@SCAPI-MODEL" => "@timestamp,LogLevel,Process,PIType,KPIName,Threshold"
		} #end scala_fields
		date_format_string => "yyyy-MM-dd'T'HH:mm:ssX"
		debug_log => "/opt/logstash/scalaout-debug.log"
		debug_level => "debug"
	} #end scala output
} #end scala output conditional


################################
# for debugging
################################

stdout
	{
	codec => rubydebug
	}
if "_grokparsefailure" in [tags] {
	file {
		codec => rubydebug
		path => "/opt/logstash/SCAPI-%{type}-debug.log"
		} # end file 
} #end conditional


} #end outputs